{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFhRffQ4IS2mYc++kSDydj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kbharath21/iiith/blob/main/AIML_Module_1_Lab_2_Machine_learning_terms_and_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AIML Module 1 - Lab 2\n",
        "# Machine learning terms and metrics\n",
        "\n",
        "\n",
        " In this lab, we will show a part of the ML pipeline by extracting features, training and testing"
      ],
      "metadata": {
        "id": "6QLsWGcWUoj4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8fIT-8kPMnCe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset =  datasets.fetch_california_housing()\n",
        "dataset.target = dataset.target.astype(np.int)\n",
        "print(dataset.data.shape)\n",
        "print(dataset.target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFJBRzmhMyPd",
        "outputId": "1a51b6b9-98ab-432b-9ab5-75712de0ee7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20640, 8)\n",
            "(20640,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-0c77f8e533aa>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dataset.target = dataset.target.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "  diff  = traindata - query\n",
        "  sq = diff*diff\n",
        "  dist = sq.sum(1)\n",
        "  label = trainlabel[np.argmin(dist)]\n",
        "  return label\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "  predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "  return predlabel"
      ],
      "metadata": {
        "id": "5LEZaUkKNDtK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomClassifier(traindata, trainlabel, testdata):\n",
        "  classes = np.unique(trainlabel)\n",
        "  rints = rng.integers(low=0, high=len(classes), size=len(testdata))\n",
        "  predlabel = classes[rints]\n",
        "  return predlabel"
      ],
      "metadata": {
        "id": "EXtPrB8ZTwm5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy(gtlabel, predlabel):\n",
        "  assert len(gtlabel)==len(predlabel), \"Length of the groundtruth labels and predicted labels should be the same\"\n",
        "  correct = (gtlabel==predlabel).sum()\n",
        "  return correct/len(gtlabel)"
      ],
      "metadata": {
        "id": "xUL7KfItUhCK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(data, label, percent):\n",
        "  rnd = rng.random(len(label))\n",
        "  split1 = rnd<percent\n",
        "  split2 = rnd>=percent\n",
        "  split1data = data[split1,:]\n",
        "  split1label = label[split1]\n",
        "  split2data = data[split2,:]\n",
        "  split2label = label[split2]\n",
        "  return split1data, split1label, split2data, split2label"
      ],
      "metadata": {
        "id": "VDRoNuXjqgmF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata, testlabel, alltraindata, alltrainlabel = split(dataset.data, dataset.target, 21/100)\n",
        "print('Number of test samples = ', len(testlabel))\n",
        "print('Number of other samples = ', len(alltrainlabel))\n",
        "print('Percent of test data = ', len(testlabel)*100/len(dataset.target),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW0xferRtcxP",
        "outputId": "f3aac824-e9e7-4148-d5cd-0f90caf1f85d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test samples =  4318\n",
            "Number of other samples =  16322\n",
            "Percent of test data =  20.920542635658915 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v8J1e65UVO4z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Ss0Z6IAGNV"
      },
      "source": [
        "## Experiments with splits\n",
        "\n",
        "Let us reserve some of our train data as a validation set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(alltraindata, alltrainlabel, 79/100)"
      ],
      "metadata": {
        "id": "6GUhnCEstfNJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainpred = NN(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Train accuracy using nearest neighbour is \", trainAccuracy)\n",
        "trainpred = RandomClassifier(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Train accuracy using random classifier is \", trainAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o40CvbzDuP1V",
        "outputId": "bf7df892-89f7-4fc9-85de-e53936ca6612"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy using nearest neighbour is  1.0\n",
            "Train accuracy using random classifier is  0.16674422211881496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour is \", valAccuracy)\n",
        "\n",
        "valpred = RandomClassifier(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using random classifier is \", valAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j8sUhReuSN3",
        "outputId": "cc887230-5448-49fd-de2c-531f64ab853f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour is  0.3427654609101517\n",
            "Validation accuracy using random classifier is  0.17386231038506417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(alltraindata, alltrainlabel, 75/100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy of nearest neighbour is \", valAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8YB7Ljru1Qt",
        "outputId": "45312c85-62fe-4334-e2cc-4c2069609724"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy of nearest neighbour is  0.34937137330754353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "print('Test accuracy is ', testAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB5IPSdtu3xP",
        "outputId": "510a70c3-43aa-4c81-9a1d-acb3ca635c93"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is  0.3432144511347846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Splits\n",
        "\n",
        "One way to get more accurate estimates for the test accuracy is by using <b>crossvalidation</b>. Here, we will try a simple version, where we do multiple train/val splits and take the average of validation accuracies as the test accuracy estimation. Here is a function for doing this. Note that this function will take a long time to execute."
      ],
      "metadata": {
        "id": "DUphWcW1vZIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AverageAccuracy(alldata, alllabel, splitpercent, iterations, classifier=NN):\n",
        "  accuracy = 0\n",
        "  for ii in range(iterations):\n",
        "    traindata, trainlabel, valdata, vallabel = split(alldata, alllabel, splitpercent)\n",
        "    valpred = classifier(traindata, trainlabel, valdata)\n",
        "    accuracy += Accuracy(vallabel, valpred)\n",
        "  return accuracy/iterations"
      ],
      "metadata": {
        "id": "v8xxApB2u5tN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Average validation accuracy is ', AverageAccuracy(alltraindata, alltrainlabel, 84/100, 10, classifier=NN))\n",
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "print('test accuracy is ',Accuracy(testlabel, testpred) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4jz2Etuu9QF",
        "outputId": "553413d6-1848-4f71-fbb6-77ac24ba750b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average validation accuracy is  0.3417117406031239\n",
            "test accuracy is  0.3432144511347846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions:\n",
        "\n",
        "1. Does averaging the validation accuracy across multiple splits give more consistent results?\n",
        "\n",
        "ans:averaging validation multiple splits , typically performed using cross-validation , provides more consistent results.helps in reducing the randomness and variability,increases robustness and reliability.\n",
        "\n",
        "2. Does it give more accurate estimate of test accuracy?\n",
        "\n",
        "ans:cross validation provides a more accurate estimate of model performance compared to a single validation split , although it remains an estimate.\n",
        "\n",
        "\n",
        "3. What is the effect of the number of iterations on the estimate? Do we get a better estimate with higher iterations?\n",
        "\n",
        "ans:the number of cross validation iterations affects estimate stability higher iterations typically improve reliability.\n",
        "\n",
        "\n",
        "4. Consider the results you got for the previous questions. Can we deal with a very small train dataset or validation dataset by increasing the iterations?\n",
        "\n",
        "ans:increasing iterations can help with small datasets but very small datasets may require alternative methods to ensure reilable model and evalutaion."
      ],
      "metadata": {
        "id": "kjpP-odZvCx6"
      }
    }
  ]
}